{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.12"},"colab":{"name":"Experiment_1_2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"08ta3u-ywqdy","executionInfo":{"status":"ok","timestamp":1599576392219,"user_tz":-480,"elapsed":4413,"user":{"displayName":"zhenglin liu","photoUrl":"","userId":"11338737901549158720"}},"outputId":"f9fed622-5cd3-4a0a-eb4e-8173a1a08195","colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["# !pip install deepdish\n","!pip install tf_slim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\r\u001b[K     |█                               | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y3aWrvvAqP-N","executionInfo":{"status":"ok","timestamp":1599576415152,"user_tz":-480,"elapsed":27119,"user":{"displayName":"zhenglin liu","photoUrl":"","userId":"11338737901549158720"}},"outputId":"c10beaeb-a7ae-4d3b-b77d-7e1d32d1f9a9","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PAJwGQ4Kwn3p"},"source":["import sys\n","sys.path.append('./drive/My Drive/project/code')\n","sys.path\n","from function import *\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# import deepdish as dd\n","import tensorflow as tf\n","import tf_slim as slim\n","import os\n","tf.compat.v1.disable_eager_execution()\n","# tf.config.set_soft_device_placement(True)\n","# tf.config.experimental.list_physical_devices('GPU')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5weo8WKwn39"},"source":["# This parameter setting is referred from https://github.com/robertocalandra/the-feeling-of-success/tree/master/manu_sawyer/src/tensorflow_model_is_gripping\n","\n","# param=during_only_v5()\n","# param=gel_im_fulldata_v5()\n","param=gel_fulldata_v5()\n","# param=im_fulldata_v5()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sW15dbBJwn4J","outputId":"9173203c-8efa-45f7-d3ed-a1cc865093b4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["init_path='./drive/My Drive/project/vgg_16.ckpt'\n","os.putenv('CUDA_VISIBLE_DEVICES', ','.join(map(str, [0,1])))\n","mkdir(param.resdir)\n","mkdir(param.dsdir)\n","mkdir(param.train_dir)\n","use_reg = True\n","restore = False\n","update_top_only=False\n","tf.compat.v1.reset_default_graph()\n","config = tf.compat.v1.ConfigProto(allow_soft_placement = True)\n","tf.Graph().as_default()\n","# with tf.Graph().as_default(), tf.device('/cpu:0'), tf.compat.v1.Session(config = config) as sess:\n","with tf.Graph().as_default(), tf.device('/device:GPU:0'), tf.compat.v1.Session(config = config) as sess:\n","\n","    inputs = read_data(param,sess)\n","    global_step = tf.compat.v1.get_variable('global_step', [], initializer = \n","                              tf.constant_initializer(0), trainable = False)\n","\n","    lr = param.base_lr * param.lr_gamma**(global_step // param.step_size)\n","\n","    if param.opt_method == 'adam':\n","      opt = tf.compat.v1.train.AdamOptimizer(lr)\n","    elif param.opt_method == 'momentum':\n","      opt = tf.compat.v1.train.MomentumOptimizer(lr, 0.9)\n","\n","    with tf.device('/device:GPU:0'):\n","      label = inputs['is_gripping']\n","\n","      logits = make_model(inputs, param, update_top_only = update_top_only, train = True, reuse = False)\n","      loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n","        logits = logits, labels = label)\n","      loss = tf.reduce_mean(loss)\n","      if use_reg:\n","        reg_losses = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES)\n","        print ('Number of regularization losses:', len(reg_losses))\n","        loss = loss + tf.add_n(reg_losses)\n","      eq = tf.equal(tf.argmax(logits, 1), label)\n","      acc = tf.reduce_mean(tf.cast(eq, tf.float32))\n","\n","    train_op = opt.minimize(loss, global_step = global_step)\n","\n","    bn_ups = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n","    print ('Batch norm updates:', len(bn_ups))\n","    train_op = tf.group(train_op, *bn_ups)\n","\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    var_list = slim.get_variables_to_restore()\n","    re=var_list\n","\n","    if restore:\n","      exclude = ['Adam', 'beta1_power', 'beta2_power', 'Momentum', 'global_step']\n","    else:\n","      exclude = ['Adam', 'beta1_power', 'beta2_power', 'Momentum', 'global_step', 'logits', 'fc8', 'fc6_', 'fc7_', 'conv6']\n","\n","    var_list = [x for x in var_list if \\\n","                not any(name in x.name for name in exclude)]\n","\n","    if restore:\n","      tf.compat.v1.train.Saver(var_list).restore(sess, tf.train.latest_checkpoint(param.train_dir))\n","    else:\n","      for base in ['im', 'depth', 'gel']:\n","          print ('Restoring:', base)\n","          mapping = {}\n","          for v in var_list:\n","            start = '%s_vgg16/' % base\n","            if v.name.startswith(start):\n","              vgg_name = v.name.replace(start, 'vgg_16/')\n","              vgg_name = vgg_name[:-2]\n","              print (vgg_name, '->', v.name)\n","              mapping[vgg_name] = v\n","          if len(mapping):\n","            tf.compat.v1.train.Saver(mapping).restore(sess, init_path)\n","\n","    tf.compat.v1.train.start_queue_runners(sess = sess)\n","    for i in range(param.train_iters):\n","      step = int(sess.run(global_step))\n","      # print(step)\n","      # if (step == 10 or step % 100 == 0) or step == param.train_iters - 1:\n","      if step % 1000 == 0 or step == param.train_iters - 1:\n","        check_path = os.path.join(mkdir(param.train_dir), 'net.tf')\n","        print ('Saving:', check_path)\n","        vs = slim.get_model_variables()\n","        tf.compat.v1.train.Saver(vs).save(sess, check_path, global_step = global_step)\n","      if step > param.train_iters:\n","        break\n","\n","      _, lr_val, loss_val, acc_val = sess.run([train_op, lr, loss, acc])\n","\n","      if step % 10 == 0:\n","        print ('Iteration %d,' % step, 'lr = ', lr_val, \\\n","              'loss:', moving_avg('loss', loss_val), 'acc:', moving_avg('acc', acc_val))\n","        sys.stdout.flush()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tf files: ['./drive/My Drive/project/result/train256_set2.tf', './drive/My Drive/project/result/train256_set3.tf', './drive/My Drive/project/result/train256_set4.tf']\n","WARNING:tensorflow:From ./drive/My Drive/project/code/function.py:447: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:112: BaseResourceVariable.count_up_to (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer Dataset.range instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From ./drive/My Drive/project/code/function.py:390: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n","group:\n","gelsightA_before (224, 224, 3)\n","gelsightA_during (224, 224, 3)\n","gelsightB_before (224, 224, 3)\n","gelsightB_during (224, 224, 3)\n","WARNING:tensorflow:From ./drive/My Drive/project/code/function.py:452: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n","reuse = False\n","False\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","True\n","False\n","True\n","Number of regularization losses: 17\n","Batch norm updates: 0\n","Restoring: im\n","Restoring: depth\n","Restoring: gel\n","vgg_16/conv1/conv1_1/weights -> gel_vgg16/conv1/conv1_1/weights:0\n","vgg_16/conv1/conv1_1/biases -> gel_vgg16/conv1/conv1_1/biases:0\n","vgg_16/conv1/conv1_2/weights -> gel_vgg16/conv1/conv1_2/weights:0\n","vgg_16/conv1/conv1_2/biases -> gel_vgg16/conv1/conv1_2/biases:0\n","vgg_16/conv2/conv2_1/weights -> gel_vgg16/conv2/conv2_1/weights:0\n","vgg_16/conv2/conv2_1/biases -> gel_vgg16/conv2/conv2_1/biases:0\n","vgg_16/conv2/conv2_2/weights -> gel_vgg16/conv2/conv2_2/weights:0\n","vgg_16/conv2/conv2_2/biases -> gel_vgg16/conv2/conv2_2/biases:0\n","vgg_16/conv3/conv3_1/weights -> gel_vgg16/conv3/conv3_1/weights:0\n","vgg_16/conv3/conv3_1/biases -> gel_vgg16/conv3/conv3_1/biases:0\n","vgg_16/conv3/conv3_2/weights -> gel_vgg16/conv3/conv3_2/weights:0\n","vgg_16/conv3/conv3_2/biases -> gel_vgg16/conv3/conv3_2/biases:0\n","vgg_16/conv3/conv3_3/weights -> gel_vgg16/conv3/conv3_3/weights:0\n","vgg_16/conv3/conv3_3/biases -> gel_vgg16/conv3/conv3_3/biases:0\n","vgg_16/conv4/conv4_1/weights -> gel_vgg16/conv4/conv4_1/weights:0\n","vgg_16/conv4/conv4_1/biases -> gel_vgg16/conv4/conv4_1/biases:0\n","vgg_16/conv4/conv4_2/weights -> gel_vgg16/conv4/conv4_2/weights:0\n","vgg_16/conv4/conv4_2/biases -> gel_vgg16/conv4/conv4_2/biases:0\n","vgg_16/conv4/conv4_3/weights -> gel_vgg16/conv4/conv4_3/weights:0\n","vgg_16/conv4/conv4_3/biases -> gel_vgg16/conv4/conv4_3/biases:0\n","vgg_16/conv5/conv5_1/weights -> gel_vgg16/conv5/conv5_1/weights:0\n","vgg_16/conv5/conv5_1/biases -> gel_vgg16/conv5/conv5_1/biases:0\n","vgg_16/conv5/conv5_2/weights -> gel_vgg16/conv5/conv5_2/weights:0\n","vgg_16/conv5/conv5_2/biases -> gel_vgg16/conv5/conv5_2/biases:0\n","vgg_16/conv5/conv5_3/weights -> gel_vgg16/conv5/conv5_3/weights:0\n","vgg_16/conv5/conv5_3/biases -> gel_vgg16/conv5/conv5_3/biases:0\n","INFO:tensorflow:Restoring parameters from ./drive/My Drive/project/vgg_16.ckpt\n","WARNING:tensorflow:From <ipython-input-6-727f5e4e3431>:73: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","Saving: ./drive/My Drive/project/result/gel-fulldata-v5/training/net.tf\n","Iteration 0, lr =  1e-05 loss: 2.7261214 acc: 0.5625\n","Iteration 10, lr =  1e-05 loss: 2.479416 acc: 0.75\n","Iteration 20, lr =  1e-05 loss: 2.460172 acc: 0.7916667\n","Iteration 30, lr =  1e-05 loss: 2.4951496 acc: 0.75\n","Iteration 40, lr =  1e-05 loss: 2.5054512 acc: 0.75\n","Iteration 50, lr =  1e-05 loss: 2.506522 acc: 0.7604167\n","Iteration 60, lr =  1e-05 loss: 2.497046 acc: 0.76785713\n","Iteration 70, lr =  1e-05 loss: 2.4816923 acc: 0.765625\n","Iteration 80, lr =  1e-05 loss: 2.4631894 acc: 0.7777778\n","Iteration 90, lr =  1e-05 loss: 2.4675033 acc: 0.7625\n","Iteration 100, lr =  1e-05 loss: 2.4934633 acc: 0.7613636\n","Iteration 110, lr =  1e-05 loss: 2.4755986 acc: 0.7708333\n","Iteration 120, lr =  1e-05 loss: 2.4810536 acc: 0.75961536\n","Iteration 130, lr =  1e-05 loss: 2.47848 acc: 0.75446427\n","Iteration 140, lr =  1e-05 loss: 2.4777005 acc: 0.75\n","Iteration 150, lr =  1e-05 loss: 2.4705572 acc: 0.75\n","Iteration 160, lr =  1e-05 loss: 2.4540348 acc: 0.7536765\n","Iteration 170, lr =  1e-05 loss: 2.4333508 acc: 0.7638889\n","Iteration 180, lr =  1e-05 loss: 2.430417 acc: 0.7631579\n","Iteration 190, lr =  1e-05 loss: 2.4271557 acc: 0.759375\n","Iteration 200, lr =  1e-05 loss: 2.4193363 acc: 0.7619048\n","Iteration 210, lr =  1e-05 loss: 2.4023936 acc: 0.7698864\n","Iteration 220, lr =  1e-05 loss: 2.3915725 acc: 0.77717394\n","Iteration 230, lr =  1e-05 loss: 2.387999 acc: 0.78125\n","Iteration 240, lr =  1e-05 loss: 2.381442 acc: 0.7825\n","Iteration 250, lr =  1e-05 loss: 2.3818316 acc: 0.77884614\n","Iteration 260, lr =  1e-05 loss: 2.3672278 acc: 0.787037\n","Iteration 270, lr =  1e-05 loss: 2.3528962 acc: 0.79464287\n","Iteration 280, lr =  1e-05 loss: 2.3496938 acc: 0.79310346\n","Iteration 290, lr =  1e-05 loss: 2.3326623 acc: 0.8\n","Iteration 300, lr =  1e-05 loss: 2.3255465 acc: 0.8044355\n","Iteration 310, lr =  1e-05 loss: 2.3160005 acc: 0.80859375\n","Iteration 320, lr =  1e-05 loss: 2.310367 acc: 0.8087121\n","Iteration 330, lr =  1e-05 loss: 2.321079 acc: 0.80330884\n","Iteration 340, lr =  1e-05 loss: 2.3161252 acc: 0.8035714\n","Iteration 350, lr =  1e-05 loss: 2.3131666 acc: 0.8038194\n","Iteration 360, lr =  1e-05 loss: 2.310777 acc: 0.8023649\n","Iteration 370, lr =  1e-05 loss: 2.3059614 acc: 0.8059211\n","Iteration 380, lr =  1e-05 loss: 2.2992046 acc: 0.80608976\n","Iteration 390, lr =  1e-05 loss: 2.292707 acc: 0.80625\n","Iteration 400, lr =  1e-05 loss: 2.2890995 acc: 0.80792683\n","Iteration 410, lr =  1e-05 loss: 2.2784853 acc: 0.8125\n","Iteration 420, lr =  1e-05 loss: 2.2736316 acc: 0.8125\n","Iteration 430, lr =  1e-05 loss: 2.275197 acc: 0.8082386\n","Iteration 440, lr =  1e-05 loss: 2.272767 acc: 0.8125\n","Iteration 450, lr =  1e-05 loss: 2.270993 acc: 0.8138587\n","Iteration 460, lr =  1e-05 loss: 2.262368 acc: 0.8178192\n","Iteration 470, lr =  1e-05 loss: 2.2561512 acc: 0.81901044\n","Iteration 480, lr =  1e-05 loss: 2.2522619 acc: 0.82015306\n","Iteration 490, lr =  1e-05 loss: 2.2469895 acc: 0.8225\n","Iteration 500, lr =  1e-05 loss: 2.243588 acc: 0.82230395\n","Iteration 510, lr =  1e-05 loss: 2.2369514 acc: 0.8233173\n","Iteration 520, lr =  1e-05 loss: 2.2345626 acc: 0.8231132\n","Iteration 530, lr =  1e-05 loss: 2.2403433 acc: 0.818287\n","Iteration 540, lr =  1e-05 loss: 2.241128 acc: 0.8159091\n","Iteration 550, lr =  1e-05 loss: 2.2350717 acc: 0.81808037\n","Iteration 560, lr =  1e-05 loss: 2.2341545 acc: 0.8190789\n","Iteration 570, lr =  1e-05 loss: 2.2288089 acc: 0.8211207\n","Iteration 580, lr =  1e-05 loss: 2.2238383 acc: 0.8220339\n","Iteration 590, lr =  1e-05 loss: 2.2156055 acc: 0.825\n","Iteration 600, lr =  1e-05 loss: 2.2103212 acc: 0.8268443\n","Iteration 610, lr =  1e-05 loss: 2.207067 acc: 0.8266129\n","Iteration 620, lr =  1e-05 loss: 2.2096117 acc: 0.8214286\n","Iteration 630, lr =  1e-05 loss: 2.206192 acc: 0.82128906\n","Iteration 640, lr =  1e-05 loss: 2.2003007 acc: 0.8230769\n","Iteration 650, lr =  1e-05 loss: 2.1984577 acc: 0.8219697\n"],"name":"stdout"}]}]}